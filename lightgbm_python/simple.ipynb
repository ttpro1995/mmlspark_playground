{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_folder=\"../data\"\n",
    "reg_train=os.path.join(parent_folder, \"regression.train.txt\")\n",
    "reg_test=os.path.join(parent_folder,\"regression.test.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['regression.test.txt', 'regression.train.txt']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(reg_train, header=None, sep='\\t')\n",
    "df_test = pd.read_csv(reg_test, header=None, sep='\\t')\n",
    "\n",
    "y_train = df_train[0]\n",
    "y_test = df_test[0]\n",
    "X_train = df_train.drop(0, axis=1)\n",
    "X_test = df_test.drop(0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.869</td>\n",
       "      <td>-0.635</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.327</td>\n",
       "      <td>-0.690</td>\n",
       "      <td>0.754</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>-1.092</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>3.102</td>\n",
       "      <td>1.354</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.359</td>\n",
       "      <td>1.498</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>1.096</td>\n",
       "      <td>-0.558</td>\n",
       "      <td>-1.588</td>\n",
       "      <td>2.173</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.139</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.799</td>\n",
       "      <td>1.471</td>\n",
       "      <td>-1.636</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.426</td>\n",
       "      <td>1.105</td>\n",
       "      <td>1.282</td>\n",
       "      <td>1.382</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.129</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.910</td>\n",
       "      <td>1.108</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.344</td>\n",
       "      <td>-0.877</td>\n",
       "      <td>0.936</td>\n",
       "      <td>1.992</td>\n",
       "      <td>0.882</td>\n",
       "      <td>1.786</td>\n",
       "      <td>-1.647</td>\n",
       "      <td>-0.942</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.678</td>\n",
       "      <td>-1.360</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.947</td>\n",
       "      <td>1.029</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.869</td>\n",
       "      <td>1.027</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.105</td>\n",
       "      <td>0.321</td>\n",
       "      <td>1.522</td>\n",
       "      <td>0.883</td>\n",
       "      <td>-1.205</td>\n",
       "      <td>0.681</td>\n",
       "      <td>-1.070</td>\n",
       "      <td>-0.922</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.374</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.756</td>\n",
       "      <td>1.361</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.838</td>\n",
       "      <td>1.133</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9   ...  \\\n",
       "0   1  0.869 -0.635  0.226  0.327 -0.690  0.754 -0.249 -1.092  0.000  ...   \n",
       "1   1  0.908  0.329  0.359  1.498 -0.313  1.096 -0.558 -1.588  2.173  ...   \n",
       "2   1  0.799  1.471 -1.636  0.454  0.426  1.105  1.282  1.382  0.000  ...   \n",
       "3   0  1.344 -0.877  0.936  1.992  0.882  1.786 -1.647 -0.942  0.000  ...   \n",
       "4   1  1.105  0.321  1.522  0.883 -1.205  0.681 -1.070 -0.922  0.000  ...   \n",
       "\n",
       "      19     20     21     22     23     24     25     26     27     28  \n",
       "0 -0.010 -0.046  3.102  1.354  0.980  0.978  0.920  0.722  0.989  0.877  \n",
       "1 -1.139 -0.001  0.000  0.302  0.833  0.986  0.978  0.780  0.992  0.798  \n",
       "2  1.129  0.900  0.000  0.910  1.108  0.986  0.951  0.803  0.866  0.780  \n",
       "3 -0.678 -1.360  0.000  0.947  1.029  0.999  0.728  0.869  1.027  0.958  \n",
       "4 -0.374  0.113  0.000  0.756  1.361  0.987  0.838  1.133  0.872  0.808  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l2: 0.243898\tvalid_0's l1: 0.492841\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's l2: 0.240605\tvalid_0's l1: 0.489327\n",
      "[3]\tvalid_0's l2: 0.236472\tvalid_0's l1: 0.484931\n",
      "[4]\tvalid_0's l2: 0.232586\tvalid_0's l1: 0.480567\n",
      "[5]\tvalid_0's l2: 0.22865\tvalid_0's l1: 0.475965\n",
      "[6]\tvalid_0's l2: 0.226187\tvalid_0's l1: 0.472861\n",
      "[7]\tvalid_0's l2: 0.223738\tvalid_0's l1: 0.469847\n",
      "[8]\tvalid_0's l2: 0.221012\tvalid_0's l1: 0.466258\n",
      "[9]\tvalid_0's l2: 0.218429\tvalid_0's l1: 0.462751\n",
      "[10]\tvalid_0's l2: 0.215505\tvalid_0's l1: 0.458755\n",
      "[11]\tvalid_0's l2: 0.213027\tvalid_0's l1: 0.455252\n",
      "[12]\tvalid_0's l2: 0.210809\tvalid_0's l1: 0.452051\n",
      "[13]\tvalid_0's l2: 0.208612\tvalid_0's l1: 0.448764\n",
      "[14]\tvalid_0's l2: 0.207468\tvalid_0's l1: 0.446667\n",
      "[15]\tvalid_0's l2: 0.206009\tvalid_0's l1: 0.444211\n",
      "[16]\tvalid_0's l2: 0.20465\tvalid_0's l1: 0.44186\n",
      "[17]\tvalid_0's l2: 0.202489\tvalid_0's l1: 0.438508\n",
      "[18]\tvalid_0's l2: 0.200668\tvalid_0's l1: 0.435919\n",
      "[19]\tvalid_0's l2: 0.19925\tvalid_0's l1: 0.433348\n",
      "[20]\tvalid_0's l2: 0.198136\tvalid_0's l1: 0.431211\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.198136\tvalid_0's l1: 0.431211\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "The rmse of prediction is: 0.44512434910807497\n"
     ]
    }
   ],
   "source": [
    "print('Starting training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=20,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=5)\n",
    "\n",
    "print('Saving model...')\n",
    "# save model to file\n",
    "gbm.save_model('simple_example_model.txt')\n",
    "\n",
    "print('Starting predicting...')\n",
    "# predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "# eval\n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6591194 , 0.52188659, 0.38268875, 0.5110434 , 0.38197134,\n",
       "       0.34018169, 0.41396358, 0.39943774, 0.6229651 , 0.47306251,\n",
       "       0.61847223, 0.70022291, 0.71058276, 0.69914022, 0.42314069,\n",
       "       0.66783381, 0.43258639, 0.56091826, 0.57046519, 0.56075766,\n",
       "       0.63319872, 0.63394932, 0.55533024, 0.53623368, 0.41009091,\n",
       "       0.57012794, 0.6020171 , 0.66496297, 0.55957183, 0.62582147,\n",
       "       0.57565458, 0.52932965, 0.52485391, 0.53569855, 0.51980793,\n",
       "       0.44330542, 0.36508028, 0.38498675, 0.54263776, 0.68376726,\n",
       "       0.23888025, 0.5774767 , 0.42391562, 0.51560301, 0.37661448,\n",
       "       0.26882572, 0.50617193, 0.53560405, 0.71074658, 0.4956262 ,\n",
       "       0.7632709 , 0.4300438 , 0.23701538, 0.70333705, 0.69718315,\n",
       "       0.54938395, 0.36687156, 0.45779262, 0.52895726, 0.6150412 ,\n",
       "       0.48265423, 0.72754265, 0.7017657 , 0.45027717, 0.71178043,\n",
       "       0.37888004, 0.57809895, 0.29833862, 0.63017501, 0.66458151,\n",
       "       0.45961202, 0.68913084, 0.74013178, 0.36842849, 0.73434287,\n",
       "       0.75401542, 0.47553897, 0.51352765, 0.67396526, 0.5059816 ,\n",
       "       0.36232515, 0.52629955, 0.70560165, 0.75072355, 0.37388771,\n",
       "       0.70900869, 0.56255599, 0.47841139, 0.49660472, 0.51591652,\n",
       "       0.59872226, 0.40869489, 0.3645835 , 0.59145789, 0.48587998,\n",
       "       0.65531704, 0.3444061 , 0.40212328, 0.7632709 , 0.37672344,\n",
       "       0.49322367, 0.53032854, 0.57734975, 0.38841599, 0.43052468,\n",
       "       0.71370107, 0.5658514 , 0.67100213, 0.45908984, 0.35949811,\n",
       "       0.47770034, 0.53860664, 0.4804635 , 0.22717313, 0.54390123,\n",
       "       0.7632709 , 0.37661448, 0.75520259, 0.40591232, 0.52009335,\n",
       "       0.40845447, 0.71625488, 0.70891776, 0.64330231, 0.41524797,\n",
       "       0.57501499, 0.64395339, 0.56036412, 0.35784307, 0.61140839,\n",
       "       0.64538488, 0.52637759, 0.38988246, 0.41662246, 0.50720394,\n",
       "       0.72754265, 0.38538299, 0.62934898, 0.50635889, 0.56288466,\n",
       "       0.43548019, 0.41661598, 0.57826918, 0.52481678, 0.46556817,\n",
       "       0.40731185, 0.44097106, 0.57340366, 0.63495349, 0.3904548 ,\n",
       "       0.43452824, 0.53787164, 0.6285882 , 0.41768279, 0.60295169,\n",
       "       0.56117129, 0.51319328, 0.5247965 , 0.53425175, 0.38459432,\n",
       "       0.7632709 , 0.72839531, 0.66440951, 0.29860124, 0.67685846,\n",
       "       0.47604949, 0.51909271, 0.73943337, 0.4170824 , 0.75546414,\n",
       "       0.757456  , 0.3507877 , 0.40138319, 0.61899867, 0.38682991,\n",
       "       0.6301115 , 0.62234885, 0.42904804, 0.32945778, 0.27217646,\n",
       "       0.26016023, 0.43849706, 0.35686271, 0.35530662, 0.24573118,\n",
       "       0.74685535, 0.60948324, 0.52336181, 0.75701687, 0.45376504,\n",
       "       0.5886153 , 0.30684282, 0.46424808, 0.41695453, 0.40556652,\n",
       "       0.63931328, 0.5219741 , 0.40901682, 0.26711342, 0.5116635 ,\n",
       "       0.40083853, 0.30750045, 0.58650744, 0.3419861 , 0.65816598,\n",
       "       0.5455619 , 0.54531911, 0.47158223, 0.7632709 , 0.27152015,\n",
       "       0.45515893, 0.70409832, 0.48076729, 0.4494446 , 0.5283931 ,\n",
       "       0.5115275 , 0.7632709 , 0.41631133, 0.4214074 , 0.44924853,\n",
       "       0.70238805, 0.27765309, 0.62425619, 0.57138979, 0.49240137,\n",
       "       0.69783299, 0.48881028, 0.52032075, 0.59056914, 0.4001433 ,\n",
       "       0.56734422, 0.419068  , 0.54584461, 0.53579315, 0.44916091,\n",
       "       0.41497048, 0.56087324, 0.48335977, 0.60249306, 0.49898068,\n",
       "       0.58808778, 0.29761261, 0.28568918, 0.43769884, 0.44094136,\n",
       "       0.43479296, 0.32450093, 0.67131649, 0.48506844, 0.33621461,\n",
       "       0.44009397, 0.41716329, 0.33417381, 0.73478962, 0.59975195,\n",
       "       0.5554807 , 0.55169485, 0.75046339, 0.386139  , 0.40686948,\n",
       "       0.49710686, 0.38094974, 0.40271955, 0.61076391, 0.4782769 ,\n",
       "       0.63942337, 0.6397927 , 0.33593498, 0.55986364, 0.22717313,\n",
       "       0.43996182, 0.52081847, 0.44160507, 0.47418265, 0.66898186,\n",
       "       0.58620984, 0.47812953, 0.71639925, 0.46596459, 0.40345727,\n",
       "       0.55582533, 0.36288366, 0.39968136, 0.42707516, 0.46297509,\n",
       "       0.44623158, 0.42845211, 0.34385818, 0.43945656, 0.64074407,\n",
       "       0.69743759, 0.2565435 , 0.43799986, 0.67883713, 0.34508564,\n",
       "       0.44301634, 0.40356873, 0.39149987, 0.41732457, 0.56990287,\n",
       "       0.52173668, 0.40036963, 0.50084646, 0.47154864, 0.37350512,\n",
       "       0.72788052, 0.43924346, 0.53104907, 0.55820702, 0.45802971,\n",
       "       0.74227397, 0.49291719, 0.4180134 , 0.7632709 , 0.42845211,\n",
       "       0.65006325, 0.57148595, 0.5869775 , 0.54993579, 0.44666615,\n",
       "       0.58208492, 0.56612067, 0.55380312, 0.69406   , 0.68885526,\n",
       "       0.34166148, 0.37110876, 0.48157866, 0.403697  , 0.50702255,\n",
       "       0.3933675 , 0.59454664, 0.55258143, 0.44961372, 0.27354871,\n",
       "       0.40310775, 0.48723105, 0.42934883, 0.74420936, 0.40661209,\n",
       "       0.61058656, 0.49816647, 0.60440077, 0.42710268, 0.64854877,\n",
       "       0.55265364, 0.57104502, 0.72364452, 0.49275135, 0.61755389,\n",
       "       0.56611647, 0.757456  , 0.64389191, 0.37600445, 0.49205255,\n",
       "       0.52252402, 0.50683697, 0.39913825, 0.69496116, 0.36842849,\n",
       "       0.40252888, 0.44018213, 0.55637491, 0.47403977, 0.39379088,\n",
       "       0.62502366, 0.39695646, 0.41817492, 0.5246962 , 0.72364452,\n",
       "       0.40000045, 0.22717313, 0.55212861, 0.70065126, 0.73975085,\n",
       "       0.6248193 , 0.58658131, 0.51691077, 0.59994258, 0.32399718,\n",
       "       0.50210402, 0.76401535, 0.74994609, 0.40413179, 0.74420936,\n",
       "       0.57042107, 0.60482048, 0.55045719, 0.3343665 , 0.42704362,\n",
       "       0.50858863, 0.48892526, 0.60484715, 0.45122102, 0.66308578,\n",
       "       0.44150601, 0.61166815, 0.64078546, 0.67932717, 0.37986215,\n",
       "       0.56053563, 0.59923085, 0.59307213, 0.64987654, 0.56981484,\n",
       "       0.73011937, 0.54883959, 0.73782903, 0.746477  , 0.41484889,\n",
       "       0.73198532, 0.45149314, 0.53221909, 0.75792809, 0.46093359,\n",
       "       0.53772855, 0.757456  , 0.44660161, 0.5028866 , 0.44538976,\n",
       "       0.7333944 , 0.46861503, 0.54519199, 0.69421732, 0.34872871,\n",
       "       0.65522199, 0.41010637, 0.53705024, 0.31814008, 0.43096408,\n",
       "       0.38777661, 0.56210962, 0.70647226, 0.75241849, 0.43677836,\n",
       "       0.72158482, 0.42649667, 0.58407036, 0.46637181, 0.76613192,\n",
       "       0.41939871, 0.50214401, 0.36413866, 0.54387971, 0.75069053,\n",
       "       0.74420936, 0.54260236, 0.68261247, 0.49446854, 0.66289319,\n",
       "       0.26859739, 0.45850128, 0.54401653, 0.56260637, 0.52025845,\n",
       "       0.35841611, 0.66254359, 0.43088235, 0.45120649, 0.50571415,\n",
       "       0.53570241, 0.5064382 , 0.45387057, 0.52148065, 0.27556792,\n",
       "       0.68751491, 0.50048894, 0.56858006, 0.45434332, 0.43400833,\n",
       "       0.44735674, 0.53102511, 0.57289022, 0.46681386, 0.43796112,\n",
       "       0.49861147, 0.55763085, 0.46535014, 0.54103586, 0.47639439,\n",
       "       0.57893249, 0.75255837, 0.51662616, 0.64472026, 0.54239965,\n",
       "       0.56455792, 0.46248015, 0.63183234, 0.64217826, 0.46941368,\n",
       "       0.65659949, 0.43742598, 0.46336184, 0.37689922, 0.7144771 ,\n",
       "       0.76613192, 0.40661209, 0.56917135, 0.38227393, 0.45718883])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rmse of prediction is: 0.44512434910807497\n",
      "The mse of prediction is: 0.19813568616888738\n"
     ]
    }
   ],
   "source": [
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)\n",
    "print('The mse of prediction is:', mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
